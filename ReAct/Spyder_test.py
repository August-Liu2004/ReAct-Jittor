import time
import requests
from bs4 import BeautifulSoup
import re
def normalize_text(s):
    if not isinstance(s, str):
        return ""
    s = s.replace('\xa0', '').replace('\u3000', '').replace('&nbsp;', '')
    s = re.sub(r"[\[\ã€][0-9a-zA-Zä¸€-é¾¥]{1,10}[\]\ã€‘]", "", s)
    return s.strip()
def extract_sentences(text):
    paragraphs = text.split("\n")
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    sentences = []
    for p in paragraphs:
        sentences += p.split('ã€‚')  # ä¸­æ–‡å¥å·
    return [s.strip() + 'ã€‚' for s in sentences if s.strip()]

class BaiduBaikeAgent:
    def __init__(self):
        super().__init__()
        self.page = None                  # å½“å‰é¡µé¢å†…å®¹ï¼ˆåŽŸå§‹ textï¼‰
        self.obs = None                   # å½“å‰ observation è¾“å‡º
        self.lookup_keyword = None       # å½“å‰ lookup å…³é”®è¯
        self.lookup_list = None          # å‘½ä¸­å¥å­åˆ—è¡¨
        self.lookup_cnt = None           # å½“å‰ lookup ç´¢å¼•
        self.steps = 0                   # æ­¥æ•°
        self.answer = None               # finish[] çš„æœ€ç»ˆå›žç­”
        self.search_time = 0             # ç´¯è®¡æœç´¢æ—¶é—´
        self.num_searches = 0 # æœç´¢æ¬¡æ•°
        self.sentences=None           
    def _get_info(self):
        return {"steps": self.steps, "answer": self.answer}
    def search_step(self, entity):
        entity_ = entity.strip().replace(" ", "+")
        url = f"https://baike.baidu.com/item/{entity_}"

        print(f"ðŸ” æ­£åœ¨æœç´¢ï¼š{entity}...")
        start = time.time()
        try:
            response = requests.get(url)
            print(response)
            self.search_time += time.time() - start
            self.num_searches += 1

            if response.status_code != 200:
                self.page = None
                self.obs = f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                return

            soup = BeautifulSoup(response.text, "html.parser")
            desc_tag = soup.find("div", class_="J-lemma-content")
            desc_intro = soup.find("div", class_="lemmaSummary_Ydljy J-summary")

            if desc_tag and desc_intro:
                content = desc_intro.get_text().strip() + "\n" + desc_tag.get_text().strip()
                self.sentences = extract_sentences(content)
                self.sentences = [normalize_text(s) for s in self.sentences]
                self.page = self.sentences
                self.obs = "âœ… å·²åŠ è½½ç™¾ç§‘å†…å®¹ï¼š\n" + ''.join(self.sentences)
                self.lookup_keyword = None
                self.lookup_list = None
                self.lookup_cnt = None
            else:
                self.page = None
                self.obs = f"â— æœªæ‰¾åˆ° {entity} çš„ç®€ä»‹ï¼Œæˆ–é¡µé¢ç»“æž„å·²å˜ã€‚"

        except Exception as e:
            self.page = None
            self.obs = f"ðŸš« ç™¾åº¦ç™¾ç§‘è¯·æ±‚å¼‚å¸¸ï¼š{e}"

    def step(self, action):
        reward = 0
        done = False
        action = action.strip()

        if self.answer is not None:  # already finished
            done = True
            return self.obs, reward, done, self._get_info()

        if action.startswith("search[") and action.endswith("]"):
            entity = action[len("search["):-1]
            self.search_step(entity)

        elif action.startswith("lookup[") and action.endswith("]"):
            keyword = action[len("lookup["):-1].strip()
            keyword = normalize_text(keyword)

            if not self.page:
                self.obs = "please search[...] firstã€‚"
            else:
                if self.lookup_keyword != keyword:  # reset
                    self.lookup_keyword = keyword
                    self.lookup_list = [
                        s for s in self.sentences
                        
                        if keyword in normalize_text(s)
                    ]
                    self.lookup_cnt = 0

                if not self.lookup_list:
                    self.obs = f"ðŸ” cannot find â€œ{keyword}â€ ã€‚"
                elif self.lookup_cnt >= len(self.lookup_list):
                    self.obs = "ðŸ”š no more sentencesã€‚\n"
                else:
                    result = self.lookup_list[self.lookup_cnt]
                    self.lookup_cnt += 1
                    self.obs = f"(Result {self.lookup_cnt} / {len(self.lookup_list)}) {result}"

        elif action.startswith("finish[") and action.endswith("]"):
            answer = action[len("finish["):-1]
            self.answer = answer
            done = True
            self.obs = f"ðŸ task over,the answer isï¼š{answer}"

        elif action.startswith("think[") and action.endswith("]"):
            self.obs = "ðŸ§  Thought acknowledged."

        else:
            self.obs = f"ðŸš«illegal actionï¼š{action}"

        self.steps += 1
        return self.obs, reward, done, self._get_info()

# âœ… ç¤ºä¾‹äº¤äº’
if __name__ == "__main__":
    agent = BaiduBaikeAgent()
    print("ðŸ§ª ç™¾åº¦ç™¾ç§‘ Agent å¯åŠ¨ã€‚æ”¯æŒæŒ‡ä»¤ï¼šsearch[...]ã€lookup[...]ã€finish[...]\n")

    while True:
        action = input(">>> ")
        if action.lower() in ["exit", "quit"]:
            print("ðŸ‘‹ å·²é€€å‡ºã€‚")
            break
        output,reward,done,info = agent.step(action)
        print(output,reward,done,info)
        if done:
            break
